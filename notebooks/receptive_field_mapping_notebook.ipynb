{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# \ud83e\udde0 Receptive Field Mapping Notebook\n",
        "\n",
        "Welcome to the **Receptive Field Mapping Notebook** \u2014 a streamlined alternative to the Streamlit app for analyzing behaviorally-relevant neural activity through high-precision video tracking and spike data alignment.\n",
        "\n",
        "This notebook mirrors the Streamlit experience step by step while letting you stay inside Jupyter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \ud83d\udd0d What This Notebook Does\n",
        "\n",
        "- **Video Analysis with DeepLabCut** \u2014 Track motion of painted markers and colored filaments using your DeepLabCut project.\n",
        "- **Model Re-training** \u2014 Re-train the supplied model with your own labels when you need to adapt the detector to a new setup.\n",
        "- **Data Cleaning & Quality Control** \u2014 Detect outliers frame-to-frame and impute them with machine-learning models.\n",
        "- **Feature Extraction & Bending Detection** \u2014 Calculate bending coefficients from tracked filament coordinates over time.\n",
        "- **Spike-Time Alignment** \u2014 Synchronize neural recordings with behavioral events, including touch timestamps and filament bending.\n",
        "- **Interactive Visualization** \u2014 Plot synchronized motion and spike activity, create homography visualizations, and export receptive field videos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \u2699\ufe0f Quick Background Summary\n",
        "\n",
        "This workflow uses **DeepLabCut** for marker tracking, aligns **neural spikes** to tracked behavioral events, and enables visualization directly in this notebook with **Plotly** and **Matplotlib** helpers from the project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Backend logic flow for creating a labeled video then post-processing.](assets/flowchart.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \u2705 Before You Start\n",
        "\n",
        "Make sure your recordings follow the setup instructions in the **Recording Instructions and Requirements** section below so that predictions and post-processing behave as expected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \ud83c\udfa5 Recording Instructions and Requirements\n",
        "\n",
        "For the recording to be properly recognized by the AI model, a few things need to be marked correctly to allow for accurate predictions and follow-up post-processing.\n",
        "\n",
        "### \ud83d\udccb Pre-filming Requirements\n",
        "\n",
        "The model is designed to detect:\n",
        "- 4 dots on the skin that represent the 4 corners of a square with sides of **1 or 2 cm**.\n",
        "- A filament with 3 **separate color zones**, allowing it to distinguish **6 points for bending**.\n",
        "\n",
        "#### \u2705 Lighting and Camera\n",
        "- Use **static, clean white lighting** for the subject.\n",
        "- Ensure a **stationary camera** throughout the recording. Either use a tripod or have steady arms.\n",
        "\n",
        "#### \u2705 Skin Dot Marking\n",
        "- Paint **4 dots** in the corners of a square using a **bright, opaque green** marker.\n",
        "  - Recommended: [Posca paint pens](https://www.posca.com/en/product/pc-5m/)\n",
        "- Avoid having other objects or markings in the frame that could be confused with the dots.\n",
        "- Example of bright green dots on skin, in a well-lit setting:\n",
        "\n",
        "![Example: Bright green dots on skin](assets/dots_example.png)\n",
        "\n",
        "#### \u2705 Filament Marking\n",
        "- Paint the filament with **2 distinct opaque colors in pattern**.\n",
        "- This allows the model to detect **6 separate points** for bend analysis.\n",
        "- Avoid similar colors or objects to the filament that could confuse the model.\n",
        "- Example of a filament painted white and dark blue:\n",
        "\n",
        "![Example: Colored filament with clear zones](assets/filament_example.png)\n",
        "\n",
        "#### \u2705 Clean the Skin\n",
        "- Ensure no old marks or blemishes interfere with detection.\n",
        "\n",
        "### \ud83c\udfac During-Filming Requirements\n",
        "- Start the video with **5 touches** at the hotspot \u2014 one per second \u2014 for synchronization with neuron data.\n",
        "- Ensure **no other filaments are visible** in the frame.\n",
        "- Confirm that the **filament is clearly visible and not blurry** during bending.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"assets/bad_bend_example_1.png\" width=\"220\"><br>\u274c Blurry region of interest</td>\n",
        "    <td><img src=\"assets/bad_bend_example_2.png\" width=\"220\"><br>\u274c Poor bend angle</td>\n",
        "    <td><img src=\"assets/good_bend_example.png\" width=\"220\"><br>\u2705 Clear, visible bend</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "> \u2705 Double-check recordings to ensure clear visibility of the bend and proper lighting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \ud83c\udfac Step 1 \u2014 DeepLabCut Video Prediction\n",
        "\n",
        "This section mirrors the Streamlit **Create Labeled Video** and **Labeling / Retraining** tabs. Use it to initialise your DeepLabCut project, preprocess a video, generate predictions, extract frames for labeling, and kick off retraining when needed.\n",
        "\n",
        "Run the setup cell below first, then interact with the widgets to walk through the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Notebook helpers (run this cell once) ---\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "import json\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, HTML, Image, Video, JSON, clear_output\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from src.train_predict import dlc_utils\n",
        "from src.post_processing.datadlc import DataDLC\n",
        "from src.post_processing.dataneuron import DataNeuron\n",
        "from src.post_processing.mergeddata import MergedData\n",
        "from src.post_processing.outlierimputer import OutlierImputer\n",
        "from src.post_processing.plotting_plotly import PlottingPlotly\n",
        "\n",
        "NOTEBOOK_STATE: dict[str, object] = {}\n",
        "\n",
        "class StreamlitNotebookShim:\n",
        "    \"\"\"Lightweight shim so Streamlit helper functions can print inside notebooks.\"\"\"\n",
        "\n",
        "    def __init__(self, state: dict[str, object]):\n",
        "        self.session_state = state\n",
        "        self._output: widgets.Output | None = None\n",
        "\n",
        "    def set_output(self, output: widgets.Output | None) -> None:\n",
        "        self._output = output\n",
        "\n",
        "    def _display(self, obj) -> None:\n",
        "        if self._output is not None:\n",
        "            with self._output:\n",
        "                display(obj)\n",
        "        else:\n",
        "            display(obj)\n",
        "\n",
        "    def _display_markdown(self, text: str) -> None:\n",
        "        self._display(Markdown(text))\n",
        "\n",
        "    def success(self, text: str) -> None:\n",
        "        self._display_markdown(f\"\u2705 {text}\")\n",
        "\n",
        "    def info(self, text: str) -> None:\n",
        "        self._display_markdown(f\"\u2139\ufe0f {text}\")\n",
        "\n",
        "    def warning(self, text: str) -> None:\n",
        "        self._display_markdown(f\"\u26a0\ufe0f {text}\")\n",
        "\n",
        "    def error(self, text: str) -> None:\n",
        "        self._display_markdown(f\"\u274c {text}\")\n",
        "\n",
        "    def write(self, obj) -> None:\n",
        "        self._display(obj)\n",
        "\n",
        "    def markdown(self, text: str) -> None:\n",
        "        self._display_markdown(text)\n",
        "\n",
        "    def title(self, text: str) -> None:\n",
        "        self._display_markdown(f\"# {text}\")\n",
        "\n",
        "    def header(self, text: str) -> None:\n",
        "        self._display_markdown(f\"## {text}\")\n",
        "\n",
        "    def subheader(self, text: str) -> None:\n",
        "        self._display_markdown(f\"### {text}\")\n",
        "\n",
        "    def image(self, image, caption: str | None = None, width: int | None = None) -> None:\n",
        "        if isinstance(image, (str, Path)):\n",
        "            img = Image(filename=str(image), width=width)\n",
        "        else:\n",
        "            img = Image(data=image, width=width)\n",
        "        self._display(img)\n",
        "        if caption:\n",
        "            self._display_markdown(f\"*{caption}*\")\n",
        "\n",
        "    def video(self, data, format: str = \"mp4\") -> None:\n",
        "        if isinstance(data, (bytes, bytearray)):\n",
        "            vid = Video(data=data, embed=True)\n",
        "        else:\n",
        "            vid = Video(filename=str(data))\n",
        "        self._display(vid)\n",
        "\n",
        "    def json(self, obj) -> None:\n",
        "        self._display(JSON(obj))\n",
        "\n",
        "    def plotly_chart(self, fig, use_container_width: bool = True) -> None:\n",
        "        fig.show()\n",
        "\n",
        "    def pyplot(self, fig, use_container_width: bool = True) -> None:\n",
        "        self._display(fig)\n",
        "\n",
        "    def stop(self) -> None:\n",
        "        raise RuntimeError(\"Execution stopped by StreamlitNotebookShim.stop().\")\n",
        "\n",
        "NOTEBOOK_STREAMLIT = StreamlitNotebookShim(NOTEBOOK_STATE)\n",
        "dlc_utils.st = NOTEBOOK_STREAMLIT\n",
        "\n",
        "def get_all_plotly_cmaps() -> dict[str, list[str]]:\n",
        "    cmap_dict: dict[str, list[str]] = {}\n",
        "    for cmap_group in [px.colors.sequential,\n",
        "                       px.colors.diverging,\n",
        "                       px.colors.cyclical,\n",
        "                       px.colors.qualitative]:\n",
        "        for name in dir(cmap_group):\n",
        "            if not name.startswith('_'):\n",
        "                cmap_dict[name] = getattr(cmap_group, name)\n",
        "    return cmap_dict\n",
        "\n",
        "def get_all_matplotlib_cmaps() -> dict[str, object]:\n",
        "    cmap_dict: dict[str, object] = {}\n",
        "    for name in dir(cm):\n",
        "        if not name.startswith('_'):\n",
        "            cmap_dict[name] = getattr(cm, name)\n",
        "    return cmap_dict\n",
        "\n",
        "PLOTLY_CMAPS = get_all_plotly_cmaps()\n",
        "MATPLOTLIB_CMAPS = get_all_matplotlib_cmaps()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- DeepLabCut prediction & retraining interface ---\n",
        "\n",
        "def build_prediction_workflow() -> widgets.Tab:\n",
        "    style = {'description_width': '160px'}\n",
        "    full_width = widgets.Layout(width='100%')\n",
        "\n",
        "    # --- Tab 1: Create labeled video ---\n",
        "    project_input = widgets.Text(\n",
        "        description='Project path:',\n",
        "        placeholder='Full path to your DeepLabCut project folder',\n",
        "        style=style,\n",
        "        layout=full_width\n",
        "    )\n",
        "    load_button = widgets.Button(description='Load project', icon='folder-open')\n",
        "    load_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    video_upload = widgets.FileUpload(\n",
        "        accept='.mp4,.avi,.mov',\n",
        "        multiple=False,\n",
        "        description='Upload video'\n",
        "    )\n",
        "    preprocess_button = widgets.Button(description='Preprocess video', icon='cogs')\n",
        "    preprocess_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    prediction_button = widgets.Button(\n",
        "        description='Run prediction & create labeled video',\n",
        "        icon='film'\n",
        "    )\n",
        "    prediction_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_load_clicked(_):\n",
        "        with load_output:\n",
        "            clear_output()\n",
        "            path_text = project_input.value.strip()\n",
        "            if not path_text:\n",
        "                print('Enter the DeepLabCut project path to continue.')\n",
        "                return\n",
        "            project_path = Path(path_text.strip('\"').strip(\"'\"))\n",
        "            if not project_path.exists():\n",
        "                print(f'Path not found: {project_path}')\n",
        "                return\n",
        "\n",
        "            config_path = project_path / 'config.yaml'\n",
        "            if not config_path.exists():\n",
        "                print(f'config.yaml not found in {project_path}')\n",
        "                return\n",
        "\n",
        "            videos_dir = project_path / 'videos'\n",
        "            videos_dir.mkdir(parents=True, exist_ok=True)\n",
        "            train_folders = sorted(project_path.glob('dlc-models-pytorch/iteration-0/*/train'))\n",
        "            train_folder = train_folders[0] if train_folders else None\n",
        "\n",
        "            NOTEBOOK_STATE['project_path'] = project_path\n",
        "            NOTEBOOK_STATE['config_path'] = config_path\n",
        "            NOTEBOOK_STATE['videos_dir'] = videos_dir\n",
        "            NOTEBOOK_STATE['training_folder'] = train_folder\n",
        "\n",
        "            NOTEBOOK_STREAMLIT.set_output(load_output)\n",
        "            try:\n",
        "                dlc_utils.init_project(str(config_path), str(project_path))\n",
        "                if train_folder:\n",
        "                    dlc_utils.clean_snapshots(str(train_folder))\n",
        "            finally:\n",
        "                NOTEBOOK_STREAMLIT.set_output(None)\n",
        "\n",
        "            summary = [\n",
        "                f'Project loaded: {project_path}',\n",
        "                f'Videos directory: {videos_dir}',\n",
        "                f\"Training folder: {train_folder if train_folder else 'not found (will be created after training)'}\"\n",
        "            ]\n",
        "            for line in summary:\n",
        "                print(line)\n",
        "\n",
        "    load_button.on_click(on_load_clicked)\n",
        "\n",
        "    def on_preprocess_clicked(_):\n",
        "        with preprocess_output:\n",
        "            clear_output()\n",
        "            project_path = NOTEBOOK_STATE.get('project_path')\n",
        "            videos_dir = NOTEBOOK_STATE.get('videos_dir')\n",
        "            if project_path is None or videos_dir is None:\n",
        "                print('Load a DeepLabCut project before preprocessing a video.')\n",
        "                return\n",
        "            if not video_upload.value:\n",
        "                print('Upload a video file to preprocess.')\n",
        "                return\n",
        "\n",
        "            upload = next(iter(video_upload.value.values()))\n",
        "            original_name = upload['metadata']['name']\n",
        "            temp_input_path = videos_dir / original_name\n",
        "            with open(temp_input_path, 'wb') as f:\n",
        "                f.write(upload['content'])\n",
        "\n",
        "            processed_video_name = f\"processed_{Path(original_name).stem}.mp4\"\n",
        "            processed_video_path = videos_dir / processed_video_name\n",
        "\n",
        "            print('Preprocessing video... this may take a while.')\n",
        "            dlc_utils.preprocess_video(str(temp_input_path), str(processed_video_path))\n",
        "            try:\n",
        "                temp_input_path.unlink()\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "            NOTEBOOK_STATE['processed_video_path'] = processed_video_path\n",
        "            NOTEBOOK_STATE['processed_video_name'] = processed_video_name\n",
        "            print(f'Video preprocessed and saved to {processed_video_path}')\n",
        "\n",
        "    preprocess_button.on_click(on_preprocess_clicked)\n",
        "\n",
        "    def on_prediction_clicked(_):\n",
        "        with prediction_output:\n",
        "            clear_output()\n",
        "            config_path = NOTEBOOK_STATE.get('config_path')\n",
        "            processed_video_path = NOTEBOOK_STATE.get('processed_video_path')\n",
        "            videos_dir = NOTEBOOK_STATE.get('videos_dir')\n",
        "\n",
        "            if None in (config_path, processed_video_path, videos_dir):\n",
        "                print('Load the project and preprocess a video before running predictions.')\n",
        "                return\n",
        "\n",
        "            NOTEBOOK_STREAMLIT.set_output(prediction_output)\n",
        "            try:\n",
        "                dlc_utils.predict_and_show_labeled_video(\n",
        "                    str(config_path),\n",
        "                    str(processed_video_path),\n",
        "                    str(videos_dir)\n",
        "                )\n",
        "                if 'h5_path' in NOTEBOOK_STATE:\n",
        "                    print(f\"Latest DLC data stored at {NOTEBOOK_STATE['h5_path']}\")\n",
        "            except Exception as exc:\n",
        "                print(f'Prediction failed: {exc}')\n",
        "            finally:\n",
        "                NOTEBOOK_STREAMLIT.set_output(None)\n",
        "\n",
        "    prediction_button.on_click(on_prediction_clicked)\n",
        "\n",
        "    tab1_box = widgets.VBox([\n",
        "        widgets.HTML('<h3>Create Labeled Video</h3><p>Load a project, upload a video, preprocess it and generate predictions.</p>'),\n",
        "        project_input,\n",
        "        load_button,\n",
        "        load_output,\n",
        "        widgets.HTML('<hr>'),\n",
        "        video_upload,\n",
        "        preprocess_button,\n",
        "        preprocess_output,\n",
        "        widgets.HTML('<hr>'),\n",
        "        prediction_button,\n",
        "        prediction_output\n",
        "    ], layout=widgets.Layout(gap='0.6em'))\n",
        "\n",
        "    # --- Tab 2: Labeling / Retraining ---\n",
        "    num_frames_slider = widgets.IntSlider(\n",
        "        value=10,\n",
        "        min=5,\n",
        "        max=50,\n",
        "        step=5,\n",
        "        description='Frames to extract',\n",
        "        style=style\n",
        "    )\n",
        "    extract_button = widgets.Button(description='Extract frames & launch Napari', icon='image')\n",
        "    extract_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    epochs_slider = widgets.IntSlider(\n",
        "        value=25,\n",
        "        min=5,\n",
        "        max=50,\n",
        "        step=5,\n",
        "        description='Pose epochs',\n",
        "        style=style\n",
        "    )\n",
        "    detector_epochs_slider = widgets.IntSlider(\n",
        "        value=50,\n",
        "        min=5,\n",
        "        max=100,\n",
        "        step=5,\n",
        "        description='Detector epochs',\n",
        "        style=style\n",
        "    )\n",
        "    retrain_button = widgets.Button(description='Retrain model', icon='redo')\n",
        "    retrain_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_extract_clicked(_):\n",
        "        with extract_output:\n",
        "            clear_output()\n",
        "            config_path = NOTEBOOK_STATE.get('config_path')\n",
        "            processed_video_path = NOTEBOOK_STATE.get('processed_video_path')\n",
        "            if None in (config_path, processed_video_path):\n",
        "                print('Load a project and preprocess a video before extracting frames.')\n",
        "                return\n",
        "            NOTEBOOK_STREAMLIT.set_output(extract_output)\n",
        "            try:\n",
        "                dlc_utils.update_num_frames2pick(str(config_path), int(num_frames_slider.value))\n",
        "                dlc_utils.run_labeling(str(config_path), str(processed_video_path))\n",
        "            except Exception as exc:\n",
        "                print(f'Frame extraction / labeling failed: {exc}')\n",
        "            finally:\n",
        "                NOTEBOOK_STREAMLIT.set_output(None)\n",
        "\n",
        "    extract_button.on_click(on_extract_clicked)\n",
        "\n",
        "    def on_retrain_clicked(_):\n",
        "        with retrain_output:\n",
        "            clear_output()\n",
        "            project_path = NOTEBOOK_STATE.get('project_path')\n",
        "            config_path = NOTEBOOK_STATE.get('config_path')\n",
        "            processed_video_path = NOTEBOOK_STATE.get('processed_video_path')\n",
        "            videos_dir = NOTEBOOK_STATE.get('videos_dir')\n",
        "            train_folder = NOTEBOOK_STATE.get('training_folder')\n",
        "\n",
        "            if None in (project_path, config_path, processed_video_path, videos_dir):\n",
        "                print('Load project, preprocess a video, and extract frames before retraining.')\n",
        "                return\n",
        "\n",
        "            if train_folder is None or not Path(train_folder).exists():\n",
        "                train_folders = sorted(Path(project_path).glob('dlc-models-pytorch/iteration-0/*/train'))\n",
        "                train_folder = train_folders[0] if train_folders else None\n",
        "                NOTEBOOK_STATE['training_folder'] = train_folder\n",
        "\n",
        "            if train_folder is None:\n",
        "                print('Could not find a training folder. Run DeepLabCut training at least once to create it.')\n",
        "                return\n",
        "\n",
        "            if not dlc_utils.is_labeling_done(str(project_path)):\n",
        "                print('No labeled data found. Label and save frames in Napari before retraining.')\n",
        "                return\n",
        "\n",
        "            NOTEBOOK_STREAMLIT.set_output(retrain_output)\n",
        "            try:\n",
        "                dlc_utils.add_video_to_config(str(config_path), str(processed_video_path))\n",
        "                dlc_utils.clean_snapshots(str(train_folder))\n",
        "                dlc_utils.delete_prev_pred(str(videos_dir))\n",
        "                dlc_utils.clear_training_datasets(str(project_path))\n",
        "\n",
        "                dlc_utils.run_retraining(\n",
        "                    str(config_path),\n",
        "                    str(train_folder),\n",
        "                    int(epochs_slider.value),\n",
        "                    int(detector_epochs_slider.value)\n",
        "                )\n",
        "\n",
        "                pose_fig = dlc_utils.show_pose_training_loss(str(train_folder))\n",
        "                if pose_fig:\n",
        "                    display(pose_fig)\n",
        "                detector_fig = dlc_utils.show_detector_training_loss(str(train_folder))\n",
        "                if detector_fig:\n",
        "                    display(detector_fig)\n",
        "\n",
        "                dlc_utils.predict_and_show_labeled_video(\n",
        "                    str(config_path),\n",
        "                    str(processed_video_path),\n",
        "                    str(videos_dir)\n",
        "                )\n",
        "            except Exception as exc:\n",
        "                print(f'Retraining failed: {exc}')\n",
        "            finally:\n",
        "                NOTEBOOK_STREAMLIT.set_output(None)\n",
        "\n",
        "    retrain_button.on_click(on_retrain_clicked)\n",
        "\n",
        "    tab2_box = widgets.VBox([\n",
        "        widgets.HTML('<h3>Labeling / Retraining</h3><p>Extract frames for Napari labeling, then retrain the model once labels are saved.</p>'),\n",
        "        num_frames_slider,\n",
        "        extract_button,\n",
        "        extract_output,\n",
        "        widgets.HTML('<hr>'),\n",
        "        epochs_slider,\n",
        "        detector_epochs_slider,\n",
        "        retrain_button,\n",
        "        retrain_output\n",
        "    ], layout=widgets.Layout(gap='0.6em'))\n",
        "\n",
        "    tabs = widgets.Tab(children=[tab1_box, tab2_box])\n",
        "    tabs.set_title(0, 'Create Labeled Video')\n",
        "    tabs.set_title(1, 'Labeling / Retraining')\n",
        "    return tabs\n",
        "\n",
        "prediction_tabs = build_prediction_workflow()\n",
        "display(prediction_tabs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### \ud83d\udcdd Napari Labeling Checklist\n",
        "\n",
        "Follow these instructions while labeling in Napari after you click **Extract frames & launch Napari** above:\n",
        "\n",
        "1. Open `Plugins \u2192 Keypoint controls` in Napari (dismiss the tutorial pop-up if it appears).\n",
        "2. Choose `File \u2192 Open File(s)\u2026`, navigate to the DeepLabCut project folder, and open `config.yaml`.\n",
        "3. Choose `File \u2192 Open Folder\u2026`, navigate into the new folder inside `labeled-data` that matches your video name, and select it. Then pick the `napari DeepLabCut` layer to start labeling.\n",
        "4. After labeling at least five frames, save with `File \u2192 Save Selected Layer(s)` while `CollectedData` is selected, then close Napari before retraining.\n",
        "\n",
        "Refer to the screenshots in the `assets/` folder (same images used in the Streamlit app) if you need a visual reminder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \ud83d\udcca Step 2 \u2014 Post Processing\n",
        "\n",
        "Use the interface below to reproduce the Streamlit **Post Processing** page. It is organised into three tabs:\n",
        "\n",
        "1. **Labeled Data** \u2014 upload DLC prediction output, clean outliers, compute bending coefficients, and apply homography.\n",
        "2. **Neuron Data** \u2014 upload neural recordings, inspect them, and downsample to match the video rate.\n",
        "3. **Merged Data** \u2014 align both data sources, visualise receptive field maps, and export animations.\n",
        "\n",
        "Run the cell below to load the widgets, then work through the tabs from left to right.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Post-processing interface ---\n",
        "\n",
        "def build_labeled_data_tab() -> widgets.Accordion:\n",
        "    style = {'description_width': '160px'}\n",
        "    full_width = widgets.Layout(width='100%')\n",
        "\n",
        "    dlc_path_text = widgets.Text(\n",
        "        description='Existing path:',\n",
        "        placeholder='Optional: /path/to/predictions.h5',\n",
        "        style=style,\n",
        "        layout=full_width\n",
        "    )\n",
        "    dlc_upload = widgets.FileUpload(\n",
        "        accept='.h5',\n",
        "        multiple=False,\n",
        "        description='Upload .h5'\n",
        "    )\n",
        "    dlc_load_button = widgets.Button(description='Load DLC data', icon='upload')\n",
        "    dlc_load_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_load_dlc(_):\n",
        "        with dlc_load_output:\n",
        "            clear_output()\n",
        "            path_value = dlc_path_text.value.strip()\n",
        "            temp_path = None\n",
        "\n",
        "            if path_value:\n",
        "                candidate = Path(path_value.strip('\"').strip(\"'\"))\n",
        "                if not candidate.exists():\n",
        "                    print(f'File not found: {candidate}')\n",
        "                    return\n",
        "                temp_path = candidate\n",
        "            elif dlc_upload.value:\n",
        "                upload = next(iter(dlc_upload.value.values()))\n",
        "                suffix = Path(upload['metadata']['name']).suffix or '.h5'\n",
        "                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n",
        "                temp_file.write(upload['content'])\n",
        "                temp_file.close()\n",
        "                temp_path = Path(temp_file.name)\n",
        "                NOTEBOOK_STATE['dlc_upload_path'] = temp_path\n",
        "                print(f'Uploaded file stored at {temp_path}')\n",
        "            else:\n",
        "                print('Provide a path or upload a DLC prediction file (.h5).')\n",
        "                return\n",
        "\n",
        "            try:\n",
        "                data_dlc = DataDLC(str(temp_path))\n",
        "                NOTEBOOK_STATE['data_dlc'] = data_dlc\n",
        "                NOTEBOOK_STATE['h5_path'] = temp_path\n",
        "                NOTEBOOK_STATE['df_square_derivative_original'] = OutlierImputer.transform_to_derivative(data_dlc.df_square.copy())\n",
        "                NOTEBOOK_STATE['df_monofil_derivative_original'] = OutlierImputer.transform_to_derivative(data_dlc.df_monofil.copy())\n",
        "                NOTEBOOK_STATE['df_square_derivative_after'] = NOTEBOOK_STATE['df_square_derivative_original'].copy()\n",
        "                NOTEBOOK_STATE['df_monofil_derivative_after'] = NOTEBOOK_STATE['df_monofil_derivative_original'].copy()\n",
        "\n",
        "                display(Markdown('**DLC square points preview (first rows):**'))\n",
        "                display(data_dlc.df_square.head())\n",
        "                display(Markdown('**Average likelihoods:**'))\n",
        "                likelihood_text = data_dlc.get_avg_likelihoods().replace('\\n', '  \\n')\n",
        "                display(Markdown(likelihood_text))\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to load DLC data: {exc}')\n",
        "\n",
        "    dlc_load_button.on_click(on_load_dlc)\n",
        "\n",
        "    imputation_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    std_square_input = widgets.FloatText(value=5.0, description='Square std', step=0.1, style=style)\n",
        "    model_square_dropdown = widgets.Dropdown(\n",
        "        options=['All Models'] + list(OutlierImputer.models.keys()),\n",
        "        value='BR',\n",
        "        description='Square model',\n",
        "        style=style\n",
        "    )\n",
        "    square_impute_button = widgets.Button(description='Impute square outliers', icon='magic')\n",
        "\n",
        "    std_filament_input = widgets.FloatText(value=5.0, description='Filament std', step=0.1, style=style)\n",
        "    model_filament_dropdown = widgets.Dropdown(\n",
        "        options=['All Models'] + list(OutlierImputer.models.keys()),\n",
        "        value='BR',\n",
        "        description='Filament model',\n",
        "        style=style\n",
        "    )\n",
        "    filament_impute_button = widgets.Button(description='Impute filament outliers', icon='magic')\n",
        "\n",
        "    def on_impute_square(_):\n",
        "        with imputation_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            model = model_square_dropdown.value\n",
        "            if model == 'All Models':\n",
        "                model = None\n",
        "            try:\n",
        "                data_dlc.impute_outliers(\n",
        "                    std_threshold=float(std_square_input.value),\n",
        "                    square=True,\n",
        "                    filament=False,\n",
        "                    model_name=model\n",
        "                )\n",
        "                NOTEBOOK_STATE['df_square_derivative_after'] = OutlierImputer.transform_to_derivative(data_dlc.df_square.copy())\n",
        "                print('Square points imputed successfully.')\n",
        "                json_path = Path('latest_square.json')\n",
        "                if json_path.exists():\n",
        "                    with open(json_path, 'r') as f:\n",
        "                        display(JSON(json.load(f)))\n",
        "            except Exception as exc:\n",
        "                print(f'Square imputation failed: {exc}')\n",
        "\n",
        "    def on_impute_filament(_):\n",
        "        with imputation_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            model = model_filament_dropdown.value\n",
        "            if model == 'All Models':\n",
        "                model = None\n",
        "            try:\n",
        "                data_dlc.impute_outliers(\n",
        "                    std_threshold=float(std_filament_input.value),\n",
        "                    square=False,\n",
        "                    filament=True,\n",
        "                    model_name=model\n",
        "                )\n",
        "                NOTEBOOK_STATE['df_monofil_derivative_after'] = OutlierImputer.transform_to_derivative(data_dlc.df_monofil.copy())\n",
        "                print('Filament points imputed successfully.')\n",
        "                json_path = Path('latest_filament.json')\n",
        "                if json_path.exists():\n",
        "                    with open(json_path, 'r') as f:\n",
        "                        display(JSON(json.load(f)))\n",
        "            except Exception as exc:\n",
        "                print(f'Filament imputation failed: {exc}')\n",
        "\n",
        "    square_impute_button.on_click(on_impute_square)\n",
        "    filament_impute_button.on_click(on_impute_filament)\n",
        "\n",
        "    derivative_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    plot_square_before_button = widgets.Button(description='Square derivative (before)', icon='line-chart')\n",
        "    plot_square_after_button = widgets.Button(description='Square derivative (after)', icon='line-chart')\n",
        "    plot_filament_before_button = widgets.Button(description='Filament derivative (before)', icon='line-chart')\n",
        "    plot_filament_after_button = widgets.Button(description='Filament derivative (after)', icon='line-chart')\n",
        "\n",
        "    def _plot_derivative(df: pd.DataFrame, title: str) -> None:\n",
        "        fig = px.line(df, title=title)\n",
        "        fig.update_layout(title_x=0.5, xaxis_title='Frame', yaxis_title='Derivative value')\n",
        "        fig.show()\n",
        "\n",
        "    def on_plot_square_before(_):\n",
        "        with derivative_output:\n",
        "            clear_output()\n",
        "            df = NOTEBOOK_STATE.get('df_square_derivative_original')\n",
        "            if df is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            _plot_derivative(df, 'Square derivative (before imputation)')\n",
        "\n",
        "    def on_plot_square_after(_):\n",
        "        with derivative_output:\n",
        "            clear_output()\n",
        "            df = NOTEBOOK_STATE.get('df_square_derivative_after')\n",
        "            if df is None:\n",
        "                print('Impute square outliers first.')\n",
        "                return\n",
        "            _plot_derivative(df, 'Square derivative (after imputation)')\n",
        "\n",
        "    def on_plot_filament_before(_):\n",
        "        with derivative_output:\n",
        "            clear_output()\n",
        "            df = NOTEBOOK_STATE.get('df_monofil_derivative_original')\n",
        "            if df is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            _plot_derivative(df, 'Filament derivative (before imputation)')\n",
        "\n",
        "    def on_plot_filament_after(_):\n",
        "        with derivative_output:\n",
        "            clear_output()\n",
        "            df = NOTEBOOK_STATE.get('df_monofil_derivative_after')\n",
        "            if df is None:\n",
        "                print('Impute filament outliers first.')\n",
        "                return\n",
        "            _plot_derivative(df, 'Filament derivative (after imputation)')\n",
        "\n",
        "    plot_square_before_button.on_click(on_plot_square_before)\n",
        "    plot_square_after_button.on_click(on_plot_square_after)\n",
        "    plot_filament_before_button.on_click(on_plot_filament_before)\n",
        "    plot_filament_after_button.on_click(on_plot_filament_after)\n",
        "\n",
        "    labeled_video_path_input = widgets.Text(\n",
        "        value=str(NOTEBOOK_STATE.get('processed_video_path', '')),\n",
        "        description='Video path:',\n",
        "        style=style,\n",
        "        layout=full_width\n",
        "    )\n",
        "    labeled_video_button = widgets.Button(description='Generate labeled video', icon='video')\n",
        "    labeled_video_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_generate_labeled_video(_):\n",
        "        with labeled_video_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            video_path_value = labeled_video_path_input.value.strip()\n",
        "            if not video_path_value:\n",
        "                print('Provide the path to the source video (preprocessed).')\n",
        "                return\n",
        "            video_path = Path(video_path_value.strip('\"').strip(\"'\"))\n",
        "            if not video_path.exists():\n",
        "                print(f'Video not found: {video_path}')\n",
        "                return\n",
        "            try:\n",
        "                video_bytes = PlottingPlotly.generate_labeled_video(data_dlc, str(video_path))\n",
        "                display(Video(data=video_bytes, embed=True))\n",
        "                NOTEBOOK_STATE['labeled_video_path'] = video_path\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to generate labeled video: {exc}')\n",
        "\n",
        "    labeled_video_button.on_click(on_generate_labeled_video)\n",
        "\n",
        "    bending_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    compute_bending_button = widgets.Button(description='Compute bending coefficients', icon='chart-line')\n",
        "    bending_plot_button = widgets.Button(description='Plot bending coefficients', icon='line-chart')\n",
        "    bending_title = widgets.Text(value='Bending Coefficients', description='Title', style=style)\n",
        "    bending_xlabel = widgets.Text(value='Frame', description='X axis', style=style)\n",
        "    bending_ylabel = widgets.Text(value='Bending value', description='Y axis', style=style)\n",
        "    bending_color_picker = widgets.ColorPicker(value='#00f900', description='Line colour')\n",
        "\n",
        "    def on_compute_bending(_):\n",
        "        with bending_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            try:\n",
        "                data_dlc.get_bending_coefficients()\n",
        "                NOTEBOOK_STATE['df_bending_coefficients'] = data_dlc.df_bending_coefficients\n",
        "                print('Bending coefficients calculated. Preview:')\n",
        "                display(data_dlc.df_bending_coefficients.head())\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to compute bending coefficients: {exc}')\n",
        "\n",
        "    def on_plot_bending(_):\n",
        "        with bending_output:\n",
        "            clear_output()\n",
        "            data = NOTEBOOK_STATE.get('df_bending_coefficients')\n",
        "            if data is None:\n",
        "                print('Compute bending coefficients first.')\n",
        "                return\n",
        "            df = pd.DataFrame({'Frame': range(len(data)), 'Bending': data})\n",
        "            fig = px.line(\n",
        "                df,\n",
        "                x='Frame',\n",
        "                y='Bending',\n",
        "                title=bending_title.value,\n",
        "                color_discrete_sequence=[bending_color_picker.value]\n",
        "            )\n",
        "            fig.update_layout(title_x=0.5, xaxis_title=bending_xlabel.value, yaxis_title=bending_ylabel.value)\n",
        "            fig.show()\n",
        "\n",
        "    compute_bending_button.on_click(on_compute_bending)\n",
        "    bending_plot_button.on_click(on_plot_bending)\n",
        "\n",
        "    homography_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    homography_video_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    homo_min_input = widgets.IntText(value=0, description='Minimum', style=style)\n",
        "    homo_max_input = widgets.IntText(value=20, description='Maximum', style=style)\n",
        "    apply_homography_button = widgets.Button(description='Apply homography', icon='project-diagram')\n",
        "    homography_plot_button = widgets.Button(description='Interactive plot', icon='map')\n",
        "    homography_video_button = widgets.Button(description='Homography animation', icon='film')\n",
        "    homography_fig_width = widgets.IntText(value=12, description='Figure width', style=style)\n",
        "    homography_fig_height = widgets.IntText(value=12, description='Figure height', style=style)\n",
        "    homography_video_fps = widgets.IntText(value=30, description='FPS', style=style)\n",
        "\n",
        "    def on_apply_homography(_):\n",
        "        with homography_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None:\n",
        "                print('Load DLC data first.')\n",
        "                return\n",
        "            try:\n",
        "                data_dlc.assign_homography_points(int(homo_min_input.value), int(homo_max_input.value))\n",
        "                data_dlc.apply_homography()\n",
        "                NOTEBOOK_STATE['homography_applied'] = True\n",
        "                print('Homography applied. Transformed monofilament preview:')\n",
        "                display(data_dlc.df_transformed_monofil.head())\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to apply homography: {exc}')\n",
        "\n",
        "    def on_plot_homography(_):\n",
        "        with homography_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Apply homography first.')\n",
        "                return\n",
        "            try:\n",
        "                fig = PlottingPlotly.plot_homography_interactive(\n",
        "                    homography_points=data_dlc.homography_points,\n",
        "                    df_transformed_monofil=data_dlc.df_transformed_monofil,\n",
        "                    title='Homography Plot',\n",
        "                    x_label='x (mm)',\n",
        "                    y_label='y (mm)',\n",
        "                    color='#00f900'\n",
        "                )\n",
        "                fig.show()\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to plot homography: {exc}')\n",
        "\n",
        "    def on_homography_video(_):\n",
        "        with homography_video_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Apply homography first.')\n",
        "                return\n",
        "            try:\n",
        "                figsize = (int(homography_fig_width.value), int(homography_fig_height.value))\n",
        "                video_bytes = PlottingPlotly.generate_homography_video(\n",
        "                    data_dlc.homography_points,\n",
        "                    data_dlc.df_transformed_monofil,\n",
        "                    fps=int(homography_video_fps.value),\n",
        "                    title='Homography Animation',\n",
        "                    x_label='x (mm)',\n",
        "                    y_label='y (mm)',\n",
        "                    color='#00f900',\n",
        "                    figsize=figsize\n",
        "                )\n",
        "                display(Video(data=video_bytes, embed=True))\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to generate homography video: {exc}')\n",
        "\n",
        "    apply_homography_button.on_click(on_apply_homography)\n",
        "    homography_plot_button.on_click(on_plot_homography)\n",
        "    homography_video_button.on_click(on_homography_video)\n",
        "\n",
        "    upload_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Load DLC data</h4>'),\n",
        "        dlc_path_text,\n",
        "        dlc_upload,\n",
        "        dlc_load_button,\n",
        "        dlc_load_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    imputation_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Outlier imputation</h4>'),\n",
        "        widgets.HBox([std_square_input, model_square_dropdown, square_impute_button]),\n",
        "        widgets.HBox([std_filament_input, model_filament_dropdown, filament_impute_button]),\n",
        "        imputation_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    derivative_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Derivative plots</h4>'),\n",
        "        widgets.HBox([plot_square_before_button, plot_square_after_button]),\n",
        "        widgets.HBox([plot_filament_before_button, plot_filament_after_button]),\n",
        "        derivative_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    labeled_video_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Regenerate labeled video</h4>'),\n",
        "        labeled_video_path_input,\n",
        "        labeled_video_button,\n",
        "        labeled_video_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    bending_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Bending coefficients</h4>'),\n",
        "        compute_bending_button,\n",
        "        widgets.HBox([bending_plot_button, bending_color_picker]),\n",
        "        widgets.HBox([bending_title, bending_xlabel, bending_ylabel]),\n",
        "        bending_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    homography_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Homography & animation</h4>'),\n",
        "        widgets.HBox([homo_min_input, homo_max_input, apply_homography_button]),\n",
        "        widgets.HBox([homography_plot_button, homography_video_button]),\n",
        "        widgets.HBox([homography_fig_width, homography_fig_height, homography_video_fps]),\n",
        "        homography_output,\n",
        "        homography_video_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    accordion = widgets.Accordion(children=[\n",
        "        upload_box,\n",
        "        imputation_box,\n",
        "        derivative_box,\n",
        "        labeled_video_box,\n",
        "        bending_box,\n",
        "        homography_box\n",
        "    ])\n",
        "    titles = [\n",
        "        'Load DLC data',\n",
        "        'Outlier imputation',\n",
        "        'Derivative plots',\n",
        "        'Regenerate labeled video',\n",
        "        'Bending coefficients',\n",
        "        'Homography'\n",
        "    ]\n",
        "    for idx, title in enumerate(titles):\n",
        "        accordion.set_title(idx, title)\n",
        "    return accordion\n",
        "\n",
        "\n",
        "def build_neuron_data_tab() -> widgets.Accordion:\n",
        "    style = {'description_width': '160px'}\n",
        "    full_width = widgets.Layout(width='100%')\n",
        "\n",
        "    neuron_path_text = widgets.Text(\n",
        "        description='Existing path:',\n",
        "        placeholder='Optional: /path/to/neuron.csv or .xlsx',\n",
        "        style=style,\n",
        "        layout=full_width\n",
        "    )\n",
        "    neuron_upload = widgets.FileUpload(\n",
        "        accept='.csv,.xlsx',\n",
        "        multiple=False,\n",
        "        description='Upload data'\n",
        "    )\n",
        "    original_fps_input = widgets.IntText(value=0, description='Original sample rate', style=style)\n",
        "    target_fps_input = widgets.IntText(value=30, description='Target sample rate', style=style)\n",
        "\n",
        "    neuron_load_button = widgets.Button(description='Load neuron data', icon='upload')\n",
        "    neuron_load_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_load_neuron(_):\n",
        "        with neuron_load_output:\n",
        "            clear_output()\n",
        "            path_value = neuron_path_text.value.strip()\n",
        "            temp_path = None\n",
        "            if path_value:\n",
        "                candidate = Path(path_value.strip('\"').strip(\"'\"))\n",
        "                if not candidate.exists():\n",
        "                    print(f'File not found: {candidate}')\n",
        "                    return\n",
        "                temp_path = candidate\n",
        "            elif neuron_upload.value:\n",
        "                upload = next(iter(neuron_upload.value.values()))\n",
        "                suffix = Path(upload['metadata']['name']).suffix or '.csv'\n",
        "                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n",
        "                temp_file.write(upload['content'])\n",
        "                temp_file.close()\n",
        "                temp_path = Path(temp_file.name)\n",
        "                NOTEBOOK_STATE['neuron_upload_path'] = temp_path\n",
        "                print(f'Uploaded file stored at {temp_path}')\n",
        "            else:\n",
        "                print('Provide a path or upload a neuron data file (.csv or .xlsx).')\n",
        "                return\n",
        "\n",
        "            if not original_fps_input.value or original_fps_input.value <= 0:\n",
        "                print('Set the original sample rate (Hz) before loading.')\n",
        "                return\n",
        "\n",
        "            try:\n",
        "                data_neuron = DataNeuron(str(temp_path), int(original_fps_input.value))\n",
        "                NOTEBOOK_STATE['neuron_data'] = data_neuron\n",
        "                NOTEBOOK_STATE['neuron_path'] = temp_path\n",
        "                display(Markdown('**Neuron data preview:**'))\n",
        "                display(data_neuron.df.head())\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to load neuron data: {exc}')\n",
        "\n",
        "    neuron_load_button.on_click(on_load_neuron)\n",
        "\n",
        "    neuron_plot_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    neuron_plot_button = widgets.Button(description='Plot neuron data', icon='area-chart')\n",
        "    neuron_plot_title = widgets.Text(value='Neuron data, original sample rate', description='Title', style=style)\n",
        "    neuron_plot_xlabel = widgets.Text(value='Index', description='X axis', style=style)\n",
        "    neuron_plot_ylabel1 = widgets.Text(value='Neuron spikes', description='Y1 axis', style=style)\n",
        "    neuron_plot_ylabel2 = widgets.Text(value='IFF', description='Y2 axis', style=style)\n",
        "    neuron_color1 = widgets.ColorPicker(value='#1f77b4', description='Spike colour')\n",
        "    neuron_color2 = widgets.ColorPicker(value='#d62728', description='IFF colour')\n",
        "    neuron_invert_checkbox = widgets.Checkbox(value=False, description='Invert IFF axis')\n",
        "\n",
        "    def on_plot_neuron(_):\n",
        "        with neuron_plot_output:\n",
        "            clear_output()\n",
        "            data_neuron: DataNeuron | None = NOTEBOOK_STATE.get('neuron_data')\n",
        "            if data_neuron is None:\n",
        "                print('Load neuron data first.')\n",
        "                return\n",
        "            try:\n",
        "                fig = PlottingPlotly.plot_dual_y_axis(\n",
        "                    df=data_neuron.df,\n",
        "                    columns=['Spike', 'IFF'],\n",
        "                    xlabel=neuron_plot_xlabel.value,\n",
        "                    ylabel_1=neuron_plot_ylabel1.value,\n",
        "                    ylabel_2=neuron_plot_ylabel2.value,\n",
        "                    title=neuron_plot_title.value,\n",
        "                    color_1=neuron_color1.value,\n",
        "                    color_2=neuron_color2.value,\n",
        "                    invert_y_2=neuron_invert_checkbox.value\n",
        "                )\n",
        "                fig.show()\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to plot neuron data: {exc}')\n",
        "\n",
        "    neuron_plot_button.on_click(on_plot_neuron)\n",
        "\n",
        "    neuron_downsample_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    neuron_downsample_button = widgets.Button(description='Downsample neuron data', icon='compress')\n",
        "    neuron_downsample_plot_button = widgets.Button(description='Plot downsampled data', icon='area-chart')\n",
        "\n",
        "    def on_downsample_neuron(_):\n",
        "        with neuron_downsample_output:\n",
        "            clear_output()\n",
        "            data_neuron: DataNeuron | None = NOTEBOOK_STATE.get('neuron_data')\n",
        "            if data_neuron is None:\n",
        "                print('Load neuron data first.')\n",
        "                return\n",
        "            if not target_fps_input.value or target_fps_input.value <= 0:\n",
        "                print('Set the target sample rate (Hz) before downsampling.')\n",
        "                return\n",
        "            try:\n",
        "                data_neuron.downsample(int(target_fps_input.value))\n",
        "                NOTEBOOK_STATE['neuron_downsampled_df'] = data_neuron.downsampled_df\n",
        "                print('Downsampled data preview:')\n",
        "                display(data_neuron.downsampled_df.head())\n",
        "            except Exception as exc:\n",
        "                print(f'Downsampling failed: {exc}')\n",
        "\n",
        "    def on_plot_downsampled(_):\n",
        "        with neuron_downsample_output:\n",
        "            clear_output()\n",
        "            data_neuron: DataNeuron | None = NOTEBOOK_STATE.get('neuron_data')\n",
        "            if data_neuron is None or data_neuron.downsampled_df is None:\n",
        "                print('Downsample the neuron data first.')\n",
        "                return\n",
        "            try:\n",
        "                fig = PlottingPlotly.plot_dual_y_axis(\n",
        "                    df=data_neuron.downsampled_df,\n",
        "                    columns=['Spike', 'IFF'],\n",
        "                    xlabel='Frame',\n",
        "                    ylabel_1='Sum of spikes',\n",
        "                    ylabel_2='Max IFF',\n",
        "                    title='Neuron data (downsampled)',\n",
        "                    color_1=neuron_color1.value,\n",
        "                    color_2=neuron_color2.value,\n",
        "                    invert_y_2=neuron_invert_checkbox.value\n",
        "                )\n",
        "                fig.show()\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to plot downsampled data: {exc}')\n",
        "\n",
        "    neuron_downsample_button.on_click(on_downsample_neuron)\n",
        "    neuron_downsample_plot_button.on_click(on_plot_downsampled)\n",
        "\n",
        "    load_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Load neuron data</h4>'),\n",
        "        neuron_path_text,\n",
        "        neuron_upload,\n",
        "        widgets.HBox([original_fps_input, target_fps_input, neuron_load_button]),\n",
        "        neuron_load_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    plot_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Visualise original data</h4>'),\n",
        "        widgets.HBox([neuron_plot_button, neuron_invert_checkbox]),\n",
        "        widgets.HBox([neuron_plot_title, neuron_plot_xlabel]),\n",
        "        widgets.HBox([neuron_plot_ylabel1, neuron_plot_ylabel2]),\n",
        "        widgets.HBox([neuron_color1, neuron_color2]),\n",
        "        neuron_plot_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    downsample_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Downsample & inspect</h4>'),\n",
        "        widgets.HBox([neuron_downsample_button, neuron_downsample_plot_button]),\n",
        "        neuron_downsample_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    accordion = widgets.Accordion(children=[load_box, plot_box, downsample_box])\n",
        "    accordion.set_title(0, 'Load neuron data')\n",
        "    accordion.set_title(1, 'Visualise original data')\n",
        "    accordion.set_title(2, 'Downsample & inspect')\n",
        "    return accordion\n",
        "\n",
        "\n",
        "def build_merged_data_tab() -> widgets.Accordion:\n",
        "    style = {'description_width': '160px'}\n",
        "\n",
        "    max_gap_fill_slider = widgets.IntSlider(value=10, min=1, max=50, step=1, description='Max gap fill', style=style)\n",
        "    threshold_slider = widgets.FloatSlider(value=0.1, min=0.0, max=1.0, step=0.05, description='Z-score threshold', style=style)\n",
        "    merge_button = widgets.Button(description='Merge DLC & neuron data', icon='link')\n",
        "    merge_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def refresh_column_options():\n",
        "        merged = NOTEBOOK_STATE.get('merged_data')\n",
        "        if merged is None:\n",
        "            return\n",
        "        columns = merged.df_merged.columns.tolist()\n",
        "        size_dropdown.options = columns\n",
        "        color_dropdown.options = columns\n",
        "        if 'Bending_ZScore' in columns:\n",
        "            size_dropdown.value = 'Bending_ZScore'\n",
        "        if 'Spike' in columns:\n",
        "            color_dropdown.value = 'Spike'\n",
        "\n",
        "    def on_merge_clicked(_):\n",
        "        with merge_output:\n",
        "            clear_output()\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            neuron_data: DataNeuron | None = NOTEBOOK_STATE.get('neuron_data')\n",
        "            if data_dlc is None or neuron_data is None:\n",
        "                print('Load DLC and neuron data before merging.')\n",
        "                return\n",
        "            try:\n",
        "                merged = MergedData(\n",
        "                    data_dlc,\n",
        "                    neuron_data,\n",
        "                    max_gap_fill=int(max_gap_fill_slider.value),\n",
        "                    threshold=float(threshold_slider.value)\n",
        "                )\n",
        "                NOTEBOOK_STATE['merged_data'] = merged\n",
        "                print('Merged data preview:')\n",
        "                display(merged.df_merged.head())\n",
        "                refresh_column_options()\n",
        "            except Exception as exc:\n",
        "                print(f'Merging failed: {exc}')\n",
        "\n",
        "    merge_button.on_click(on_merge_clicked)\n",
        "\n",
        "    bending_toggle = widgets.Checkbox(value=True, description='Apply bending threshold')\n",
        "    spikes_toggle = widgets.Checkbox(value=True, description='Require spikes')\n",
        "    filter_button = widgets.Button(description='Preview filtered rows', icon='table')\n",
        "    filter_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "\n",
        "    def on_filter_clicked(_):\n",
        "        with filter_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            if merged is None:\n",
        "                print('Merge the data first.')\n",
        "                return\n",
        "            df = merged.threshold_data(bending=bending_toggle.value, spikes=spikes_toggle.value)\n",
        "            print(f'Rows after filtering: {len(df)}')\n",
        "            display(df.head())\n",
        "\n",
        "    filter_button.on_click(on_filter_clicked)\n",
        "\n",
        "    plot_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    kde_button = widgets.Button(description='Interactive KDE', icon='satellite')\n",
        "    scatter_button = widgets.Button(description='Interactive scatter', icon='braille')\n",
        "    plot_title_input = widgets.Text(value='KDE / Scatter Plot', description='Title', style=style)\n",
        "    plot_xlabel_input = widgets.Text(value='x (mm)', description='X axis', style=style)\n",
        "    plot_ylabel_input = widgets.Text(value='y (mm)', description='Y axis', style=style)\n",
        "    size_dropdown = widgets.Dropdown(description='Size column')\n",
        "    color_dropdown = widgets.Dropdown(description='Colour column')\n",
        "    plotly_cmap_dropdown = widgets.Dropdown(options=sorted(PLOTLY_CMAPS.keys()), value='Viridis', description='Plotly cmap')\n",
        "    plotly_spikes_cmap_dropdown = widgets.Dropdown(options=sorted(PLOTLY_CMAPS.keys()), value='Inferno', description='Spikes cmap')\n",
        "    bw_bending_input = widgets.FloatText(value=0.1, description='Bandwidth (bending)', style=style)\n",
        "    bw_spikes_input = widgets.FloatText(value=0.1, description='Bandwidth (spikes)', style=style)\n",
        "    bw_threshold_input = widgets.FloatText(value=0.05, description='% threshold', style=style)\n",
        "\n",
        "    def on_kde_clicked(_):\n",
        "        with plot_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if merged is None or data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Merge data and apply homography before plotting.')\n",
        "                return\n",
        "            try:\n",
        "                fig = PlottingPlotly.plot_kde_density_interactive(\n",
        "                    merged,\n",
        "                    x_col='tf_FB2_x',\n",
        "                    y_col='tf_FB2_y',\n",
        "                    homography_points=data_dlc.homography_points,\n",
        "                    bending=bending_toggle.value,\n",
        "                    spikes=spikes_toggle.value,\n",
        "                    title=plot_title_input.value,\n",
        "                    xlabel=plot_xlabel_input.value,\n",
        "                    ylabel=plot_ylabel_input.value,\n",
        "                    cmap_bending=plotly_cmap_dropdown.value,\n",
        "                    cmap_spikes=plotly_spikes_cmap_dropdown.value,\n",
        "                    bw_bending=float(bw_bending_input.value),\n",
        "                    bw_spikes=float(bw_spikes_input.value),\n",
        "                    threshold_percentage=float(bw_threshold_input.value)\n",
        "                )\n",
        "                fig.show()\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to plot KDE: {exc}')\n",
        "\n",
        "    def on_scatter_clicked(_):\n",
        "        with plot_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if merged is None or data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Merge data and apply homography before plotting.')\n",
        "                return\n",
        "            try:\n",
        "                fig = PlottingPlotly.plot_scatter_interactive(\n",
        "                    merged,\n",
        "                    x_col='tf_FB2_x',\n",
        "                    y_col='tf_FB2_y',\n",
        "                    homography_points=data_dlc.homography_points,\n",
        "                    size_col=size_dropdown.value,\n",
        "                    color_col=color_dropdown.value,\n",
        "                    bending=bending_toggle.value,\n",
        "                    spikes=spikes_toggle.value,\n",
        "                    title=plot_title_input.value,\n",
        "                    xlabel=plot_xlabel_input.value,\n",
        "                    ylabel=plot_ylabel_input.value,\n",
        "                    cmap=plotly_cmap_dropdown.value\n",
        "                )\n",
        "                fig.show()\n",
        "            except Exception as exc:\n",
        "                print(f'Failed to plot scatter: {exc}')\n",
        "\n",
        "    kde_button.on_click(on_kde_clicked)\n",
        "    scatter_button.on_click(on_scatter_clicked)\n",
        "\n",
        "    animation_output = widgets.Output(layout={'border': '1px solid #ddd', 'padding': '0.2em'})\n",
        "    rf_video_button = widgets.Button(description='RF map animation (video)', icon='play')\n",
        "    scatter_video_button = widgets.Button(description='Scatter animation (video)', icon='play-circle')\n",
        "    scroll_video_button = widgets.Button(description='Scrolling overlay video', icon='video-camera')\n",
        "    animation_fps_input = widgets.IntText(value=30, description='Video FPS', style=style)\n",
        "    animation_fig_width = widgets.IntText(value=12, description='Figure width', style=style)\n",
        "    animation_fig_height = widgets.IntText(value=12, description='Figure height', style=style)\n",
        "\n",
        "    def on_rf_video(_):\n",
        "        with animation_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if merged is None or data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Merge data and apply homography before generating the animation.')\n",
        "                return\n",
        "            try:\n",
        "                figsize = (int(animation_fig_width.value), int(animation_fig_height.value))\n",
        "                video_bytes = PlottingPlotly.plot_rf_mapping_animated(\n",
        "                    merged,\n",
        "                    x_col='tf_FB2_x',\n",
        "                    y_col='tf_FB2_y',\n",
        "                    homography_points=data_dlc.homography_points,\n",
        "                    size_col=size_dropdown.value,\n",
        "                    color_col=color_dropdown.value,\n",
        "                    title=plot_title_input.value,\n",
        "                    bending=bending_toggle.value,\n",
        "                    spikes=spikes_toggle.value,\n",
        "                    xlabel=plot_xlabel_input.value,\n",
        "                    ylabel=plot_ylabel_input.value,\n",
        "                    fps=int(animation_fps_input.value),\n",
        "                    figsize=figsize,\n",
        "                    cmap=plotly_cmap_dropdown.value\n",
        "                )\n",
        "                display(Video(data=video_bytes, embed=True))\n",
        "            except Exception as exc:\n",
        "                print(f'RF map animation failed: {exc}')\n",
        "\n",
        "    def on_scatter_video(_):\n",
        "        with animation_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            data_dlc: DataDLC | None = NOTEBOOK_STATE.get('data_dlc')\n",
        "            if merged is None or data_dlc is None or data_dlc.homography_points is None:\n",
        "                print('Merge data and apply homography before generating the animation.')\n",
        "                return\n",
        "            if not hasattr(PlottingPlotly, 'generate_scatter_plot_animation'):\n",
        "                print('Scatter animation helper is not available in this repository version.')\n",
        "                return\n",
        "            try:\n",
        "                figsize = (int(animation_fig_width.value), int(animation_fig_height.value))\n",
        "                video_bytes = PlottingPlotly.generate_scatter_plot_animation(\n",
        "                    merged,\n",
        "                    x_col='tf_FB2_x',\n",
        "                    y_col='tf_FB2_y',\n",
        "                    homography_points=data_dlc.homography_points,\n",
        "                    size_col=size_dropdown.value,\n",
        "                    color_col=color_dropdown.value,\n",
        "                    bending=bending_toggle.value,\n",
        "                    spikes=spikes_toggle.value,\n",
        "                    title=plot_title_input.value,\n",
        "                    xlabel=plot_xlabel_input.value,\n",
        "                    ylabel=plot_ylabel_input.value,\n",
        "                    cmap=plotly_cmap_dropdown.value,\n",
        "                    fps=int(animation_fps_input.value),\n",
        "                    figsize=figsize\n",
        "                )\n",
        "                display(Video(data=video_bytes, embed=True))\n",
        "            except Exception as exc:\n",
        "                print(f'Scatter animation failed: {exc}')\n",
        "\n",
        "    def on_scroll_video(_):\n",
        "        with animation_output:\n",
        "            clear_output()\n",
        "            merged: MergedData | None = NOTEBOOK_STATE.get('merged_data')\n",
        "            video_path = NOTEBOOK_STATE.get('labeled_video_path')\n",
        "            if merged is None:\n",
        "                print('Merge data first.')\n",
        "                return\n",
        "            if video_path is None or not Path(video_path).exists():\n",
        "                print('Provide a labeled video path in the DLC tab before generating the scrolling overlay video.')\n",
        "                return\n",
        "            try:\n",
        "                video_bytes = PlottingPlotly.generate_scroll_over_video(\n",
        "                    merged_data=merged,\n",
        "                    columns=['Bending_ZScore', 'Spike'],\n",
        "                    video_path=str(video_path),\n",
        "                    color_1='#1f77b4',\n",
        "                    color_2='#d62728',\n",
        "                    title='Scrolling Overlay Video'\n",
        "                )\n",
        "                display(Video(data=video_bytes, embed=True))\n",
        "            except Exception as exc:\n",
        "                print(f'Scrolling overlay failed: {exc}')\n",
        "\n",
        "    rf_video_button.on_click(on_rf_video)\n",
        "    scatter_video_button.on_click(on_scatter_video)\n",
        "    scroll_video_button.on_click(on_scroll_video)\n",
        "\n",
        "    merge_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Merge DLC & neuron data</h4>'),\n",
        "        widgets.HBox([max_gap_fill_slider, threshold_slider, merge_button]),\n",
        "        merge_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    filter_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Filter preview</h4>'),\n",
        "        widgets.HBox([bending_toggle, spikes_toggle, filter_button]),\n",
        "        filter_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    plot_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Interactive plots</h4>'),\n",
        "        widgets.HBox([kde_button, scatter_button]),\n",
        "        widgets.HBox([plot_title_input, plot_xlabel_input, plot_ylabel_input]),\n",
        "        size_dropdown,\n",
        "        color_dropdown,\n",
        "        plotly_cmap_dropdown,\n",
        "        plotly_spikes_cmap_dropdown,\n",
        "        widgets.HBox([bw_bending_input, bw_spikes_input, bw_threshold_input]),\n",
        "        plot_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    animation_box = widgets.VBox([\n",
        "        widgets.HTML('<h4>Animations & videos</h4>'),\n",
        "        widgets.HBox([rf_video_button, scatter_video_button, scroll_video_button]),\n",
        "        widgets.HBox([animation_fps_input, animation_fig_width, animation_fig_height]),\n",
        "        animation_output\n",
        "    ], layout=widgets.Layout(gap='0.4em'))\n",
        "\n",
        "    accordion = widgets.Accordion(children=[merge_box, filter_box, plot_box, animation_box])\n",
        "    accordion.set_title(0, 'Merge data')\n",
        "    accordion.set_title(1, 'Filter preview')\n",
        "    accordion.set_title(2, 'Interactive plots')\n",
        "    accordion.set_title(3, 'Animations & videos')\n",
        "    return accordion\n",
        "\n",
        "\n",
        "post_processing_tabs = widgets.Tab(children=[\n",
        "    build_labeled_data_tab(),\n",
        "    build_neuron_data_tab(),\n",
        "    build_merged_data_tab()\n",
        "])\n",
        "post_processing_tabs.set_title(0, 'Labeled Data')\n",
        "post_processing_tabs.set_title(1, 'Neuron Data')\n",
        "post_processing_tabs.set_title(2, 'Merged Data')\n",
        "\n",
        "display(post_processing_tabs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## \u2705 Next Steps\n",
        "\n",
        "- Step through the tabs from left to right to mirror the Streamlit workflow.\n",
        "- Re-run individual widget sections whenever you adjust parameters; results will update live.\n",
        "- Generated videos can be saved by right-clicking in the output or by adapting the helper functions to write to disk.\n",
        "- Once satisfied, proceed with your downstream analysis or export the processed dataframes for further work.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}